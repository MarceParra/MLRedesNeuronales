# ============================================================
#  Perceptr贸n Simple para Clasificar Naranjas y Limones
# Autor: Ing. Marcela Parra, Mg.
# ============================================================

import numpy as np
from collections import Counter
from sklearn.model_selection import train_test_split
from random import shuffle
import matplotlib.pyplot as plt
import matplotlib.cm as cm

# Funci贸n para generar puntos aleatorios dentro de un c铆rculo.
# Cada punto tiene coordenadas x,y distribuidas uniformemente.
def points_within_circle(radius, center=(0, 0), number_of_points=100):
    cx, cy = center
    # Generar radios aleatorios con ra铆z cuadrada para distribuci贸n uniforme en 谩rea
    r = radius * np.sqrt(np.random.random(number_of_points))
    # ngulo aleatorio entre 0 y 2
    theta = np.random.random(number_of_points) * 2 * np.pi
    # Coordenadas x,y de los puntos generados
    x = cx + r * np.cos(theta)
    y = cy + r * np.sin(theta)
    return x, y

# Clase Perceptr贸n para clasificar puntos en dos categor铆as (naranjas y limones)
class Perceptron:
    # Inicializador con pesos iniciales y tasa de aprendizaje para ajustar pesos
    def __init__(self, weights, learning_rate=0.1):
        self.weights = np.array(weights)  # Pesos iniciales como array numpy
        self.learning_rate = learning_rate  # Factor para controlar velocidad de aprendizaje

    # Funci贸n escal贸n para decidir la salida final: 0 o 1 seg煤n el umbral cero
    @staticmethod
    def unit_step_function(x):
        return 0 if x < 0 else 1

    # M茅todo que calcula la salida del perceptr贸n para un dato de entrada
    def __call__(self, in_data):
        # Producto elemento a elemento entre pesos y entradas
        weighted_sum = (self.weights * in_data).sum()  # Suma ponderada total
        return Perceptron.unit_step_function(weighted_sum)  # Salida binaria 0 o 1

    # M茅todo para ajustar los pesos basado en el error entre salida esperada y calculada
    def adjust(self, target_result, calculated_result, in_data):
        # Convertir entrada a array si no lo es
        if not isinstance(in_data, np.ndarray):
            in_data = np.array(in_data)
        # Calcular error simple (target - calculado)
        error = target_result - calculated_result
        # Si hay error, corregir pesos
        if error != 0:
            correction = error * in_data * self.learning_rate  # Ajuste proporcional al error y entrada
            self.weights += correction  # Actualizar pesos sumando la correcci贸n

    # M茅todo para evaluar cu谩ntos datos fueron clasificados correctamente
    def evaluate(self, data, labels):
        evaluation = Counter()
        for i in range(len(data)):
            label = int(round(self(data[i]), 0))  # Predecir etiqueta para cada dato
            if label == labels[i]:
                evaluation["correct"] += 1  # Contar aciertos
            else:
                evaluation["wrong"] += 1  # Contar errores
        total = evaluation["correct"] + evaluation["wrong"]
        accuracy = (evaluation["correct"] / total) * 100  # Calcular porcentaje de acierto
        print(f"Aciertos: {evaluation['correct']} de {total} ({accuracy:.2f}%)")
        return evaluation

# ------------------------------------------------------------
# Generar datos para naranjas y limones usando la funci贸n de puntos en c铆rculo
oranges_x, oranges_y = points_within_circle(2.5, center=(8, 2), number_of_points=100)
lemons_x, lemons_y = points_within_circle(2.5, center=(2, 9), number_of_points=100)

# Combinar coordenadas en pares (x,y)
oranges = list(zip(oranges_x, oranges_y))
lemons = list(zip(lemons_x, lemons_y))

# Crear lista con datos etiquetados: 0 para naranja, 1 para lim贸n
labelled_data = list(zip(oranges + lemons, [0] * len(oranges) + [1] * len(lemons)))
shuffle(labelled_data)  # Mezclar datos para aleatoriedad

# Separar datos y etiquetas en dos listas separadas
data, labels = zip(*labelled_data)

# Dividir datos en conjuntos de entrenamiento (80%) y prueba (20%)
train_data, test_data, train_labels, test_labels = train_test_split(
    data, labels, train_size=0.8, test_size=0.2, random_state=42)

# Crear instancia del perceptr贸n con pesos iniciales peque帽os y tasa de aprendizaje
p = Perceptron(weights=[0.1, 0.1], learning_rate=0.3)

# Entrenamiento del perceptr贸n: ajustar pesos usando datos de entrenamiento
for i in range(len(train_data)):
    p.adjust(train_labels[i], p(train_data[i]), train_data[i])

# Evaluar el desempe帽o del modelo con datos de entrenamiento
print("Evaluaci贸n en datos de entrenamiento:")
p.evaluate(train_data, train_labels)

# Evaluar el desempe帽o con datos de prueba para validar generalizaci贸n
print("\nEvaluaci贸n en datos de prueba:")
p.evaluate(test_data, test_labels)

# Mostrar los pesos finales luego del entrenamiento
print(f"\nPesos finales: {p.weights}")

# ------------------------------------------------------------
# Visualizaci贸n de los datos y la frontera de decisi贸n

X = np.arange(0, 10)  # Crear rango para eje X en gr谩fico

# Separar puntos de limones y naranjas para graficar con color distinto
lemons = [train_data[i] for i in range(len(train_data)) if train_labels[i] == 1]
lemons_x, lemons_y = zip(*lemons)
oranges = [train_data[i] for i in range(len(train_data)) if train_labels[i] == 0]
oranges_x, oranges_y = zip(*oranges)

fig, ax = plt.subplots()
# Graficar puntos de naranja en color naranja
ax.scatter(oranges_x, oranges_y, c="orange", label="Naranjas")
# Graficar puntos de lim贸n en color amarillo
ax.scatter(lemons_x, lemons_y, c="yellow", label="Limones")

# Extraer pesos para calcular pendiente de la frontera de decisi贸n
w1, w2 = p.weights
m = -w1 / w2  # Pendiente de la l铆nea que separa clases

# Graficar l铆nea de frontera de decisi贸n
ax.plot(X, m * X, label="Frontera de decisi贸n", linewidth=2)

# A帽adir leyenda y etiquetas
ax.legend()
ax.set_title("Clasificaci贸n de Naranjas y Limones usando Perceptr贸n")
ax.set_xlabel("Caracter铆stica 1")
ax.set_ylabel("Caracter铆stica 2")
ax.grid(True)

# Mostrar gr谩fico
plt.show()